{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from googletrans import Translator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = \"서비스(신문기사, 저널)\t\t심리(Weibo에서 언급된 주제에 대한 Root user의 심리), 사고(Weibo에서 언급된 주제에 대한 Root user의 사고)\t사건(2010 칠레 대지진, parking day)\t장소(트윗이 발생한 장소)\t서비스, 제품\t\t사건(2012 미국대선)\t서비스(24/7 news channels-USA/Asia-비디오 및 오디오자료 포함)\t서비스(reddit에서 제공되는 뉴스 기사) 복합속성: 대선후보 트윗에서 다루어진 키워드들\t\t\t\t\t\t\t\t 평가(신문기사에 대한 코멘트)\t의견(대선 후보들의 정책-공략),  평가(대선 후보 트윗에 대한 사용자의 평가 ex. like)\t의견: Comments 리포스팅 된 Weibo에 대한 사용자의 의견\t의견 및 감정(주어진 사건(칠레 대지진, parking day)에 대해 트위터 사용자들이 남기는 의견 및 감정)\t의견(각 장소에서 발생하는(그 지역과 관련된) 트윗 메시지)\t감정(대상에 대해 느끼는 감정)\t의견(트윗에서 추출되는 여러 사용자들의 의견 - PRISM 데이터, 마이크로소프트에 대한 사람들의 의견)\t의견(트윗에서 정치적으로 경쟁하거나 협력에 관해서 언급한 문장과 키워드)\t입장, 태도 (뉴스에서 전하는 다양한 소식, 저널리즘의 태도-캡션)\t평가(독자들이 reddit에서 다루어지는 기사 내용이 루머인지 아닌지를 판단함) 키 플레이어(유명인), 단체, 일반인: 신문기사에 대해 코멘트를 남기는 주체\t키 플레이어(도널드 트럼프, 힐러리 클린턴)\t글 작성자: Root user(원본 Weibo를 작성한 Weibo 사용자)  키플레이어: Root weibo를 많이 리포스팅 한 사용자\t글 작성자(주체): 트위터 사용자\t\t글 작성자(주체)\t글 작성자(주체)(트윗을 남기는 사용자들)\t키플레이어(유명인): topic leaders\t\t 축적(시간이 지남에 따라 대상 기사에 대한 코멘트가 점점 늘어나면서 쌓임) 성장/축소(의견의 확산에 따른 코멘트 양의 성장 축소를 나타내고자 함)\t축적(발화자들의 의견이 시간에 따라 축적됨)\t축적: 시간에 따른 Weibo 확산 과정 구조를 나타냄 성장/축소, 반복: 오리지널 웨이보의 리포스팅 패턴의 성장과 축소, 반복 패턴을 나타냄\t성장/축소: 시간에 따라서 특정 사건에 대해 언급한 빈도수 변화 연속성(각 지역의 트윗 발생 빈도를 시간에 따라 연속적으로 나타내고자 함)\t연속성(감정의 변화를 시간에 따라 연속적으로 나타내고자 함)\t성장/축소(특정 극성을 나타내는 트윗 의견들의 확산 과정을 표현하는 시간)\t연속성: 시간에 따라 전개되는 coopetition의 흐름을 나타내고자 함\t연속성: news의 토픽의 흐름을 나타내기 위해 표현되는 기간의 연속성\t연속성(루머의 빈도 흐름을 나타내기 위해 news를 수집한 기간)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intermediation = \"대상에 대해 나타나는 감정이 무슨 의미(원인)을 가지고 있는지를 탐자히고자 함\t\t\t\tnews에서 자주 돋보이는 토픽 흐름에 영향을 주는 증거(토픽과 관련된 이벤트, 사람, 위치, 시간)를 정리하고자 함\t각 토론자 및 의견에 대해서 논쟁 패턴을 감지해야함\t\t\t\t\t\t\t\t트윗에서 다루는 여러 주제들을 모두 시각화하여 분석하는 것이 필요함\t\t\t\t\t\t\t\t제공되는 뉴스 및 뉴스에 대한 다수의 평가 정보가 루머인지의 여부를 분석하고자 함 후보가 남긴 키워드 중 중요한 내용만 정리하여 제시\t\t트윗 문장에서 대상이되는 사건과 관련된 의견을 요약하고자 함 \t각 지역에서 발생한 트윗의 내용을 요약하고자 함\t\t트윗 텍스트의 극성 및 키워드 정보를 요약하고자 함\t2012년 대선과 관련된 정치적 협력 및 분쟁에 대한 키워드를 요약하고자 함\t\t사람들이 주고받는 트윗 내용 중, 토픽, 키워드, 이모티콘과 같은 여러 측면을 다양한 수준에서 수집하여 시각화하고자 함\t\t\t\t\t\t대상에 대해 느끼는 감정을 정리하고 분류하고자 함\t\t\t\t중국어 사용자가 대다수인 소셜미디어 Weibo 게시물에서 나타나는 의견 정보를 분석하고 처리하는 업무 \t\t\t\t두 후보자의 트윗 내용을 서로 비교함\t\t\t특정 시간에 발생하는 트윗의 내용을 지역끼리 비교하고자 함\t\t\t서로 다른 성향을 가진 (경쟁이 일어나는) 의견보유자들의 트윗 텍스트 키워드를 비교하고자 함\t\t각 뉴스 데이터 토픽에 대해서 카운팅 되는 루머 정보들을 서로 비교하고자 함 동일한 토픽 내에서 사람들이 해당 루머 정보에 대해서 대처하는 평가 방식(루머를 질책함, 루머를 무시함, 루머를 믿고 퍼뜨림)의 양을 서로 비교하고자 함 발행된 신문기사에 대해서 시간에 따라 축적되는 코멘트와 평가를 분석하고자 함\t시간에 따라 축적되는 트윗을 분석함\t하나의 Weibo의 시간에 따른 확산 과정을 여러 단계로 보여줌, 각각의 단계에서는 다른 리포스팅 태도와 주제, Key player가 드러남.\t시간에 따라 등장하는 사건 관련 키워드의 빈도수를 시각화하고자 함\t시간에 따라 각 장소에서 발생하는 트윗의 패턴을 분석하고자 함\t시간에 따라 변화하는 감정의 패턴을 분석하고자 함\t시간에 따라 확산되는 트윗의 양, 극성 변화의 흐름을 분석하고자 함\t시간의 연속성에 따라 기록되는 coopetition(경쟁-협력) 패턴의 분열과 화합과정, 그리고 자주발생하는 패턴을 분석하고자 함\t시간의 연속성에 따라 기록되는 다양한 뉴스 주제들을 분석하고자 함\t시간의 연속성 구간에 따라 변화하는 루머 관련 정보의 변동성을 분석하고자 함 topic leader들이 분열이 일어나거나 협력이 일어나는 부분을 탐색하여 분석하고자 함한 weibo의 확산 과정에서 Root Weibo를 작성한 Root user, Root Weibo를 리포스팅에 영향을 많이 끼친 사용자인 Key Player를 찾을 수 있음. \t가장 활발히 활동하는 유저를 랭크하고자 함\t\t\t중요한 극성 변환에 영향을 주는 사용자 그룹을 나타내고자 함\t\t가장 두드러진 뉴스 사건을 찾고자 함\t각 기간별로 코멘트를 남긴 사람이나, 코멘트를 쉽게 탐색할 수 있도록 함\t\t다양한 역할과 행동을 가지고 있는 weibo 사용자들을 확인하고 탐색하고자함. Overview 를 제공하여 리포스팅 구조를 탐색할 수 있음.\t많은 참가자들이 특정 사건에 대해서 시간별로 남기는 트윗의 추이 및 감성 정보를 손쉽게 파악하고자 함\t시간-장소-의견' 의 개념을 손쉽게 탐색할수 있도록 함\t\t\t\t각 구간마다 두드러지는 토픽 및 그 토픽과 관련된 뉴스 장면들을 손쉽게 탐색할 수 있도록 함\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Representation = \"자연경관: 폭포(기사에 대한 여러 의견보유자의 코멘트를 시간별로 퍼뜨리는 형상을 폭포로 표현함)\t자연경관: 강(River) - 각 후보자들이 특정 날짜에 남긴 트윗의 총량을 나타냄\t자연경관: Lake (호수는 강의 발원지 역할을 하며, 호수가 주변 땅에 물을 공급하는 것처럼 키 플레이어는 다른 사용자가 Weibo를 리 포스팅 할 수 있도록 정보를 제공한다.)  River: 각 호수(Key pkayer)들을 연결 자연경관: 강(river)- 이벤트와 관련된 topic의 빈도수를 나타내고자 함\t자연경관(강-시간에 따라 발생하는 트윗 양의 흐름을 나타내고자 함)\t자연경관(강-시간에 따라 발생하는 각 토픽에 대한 감정의 빈도 흐름을 나타냄)\t자연경관(강: 특정 대상에 대해서 남겨진 트윗의 극성 변화 및 양의 변화의 흐름을 강으로 은유함)\t자연경관(강: 시간에 따른 분열과 협력관계를 강의흐름으로 나타냄)\t자연경관(강: 뉴스 토픽들의 빈도를 강으로 표시함)\t자연경관(강: 각 토픽에서 추출되는 루머 정보의 양적 변화를 강으로 표시함) 기하도형(사각형): 코멘트를 남기는 의견보유자를 나타냄\t건축물: 다리(Bridge)- 각 후보자들의 트윗을 나타냄  구조물: 다리의 지지대 - 후보자 트윗에 대한 사용자들의 평가 정보(like)를 나타냄\t지도:  County (리 포스팅 트리에서 키 플레이어가 올리지 않은 Weibo를 나타냄. 영향력 있는 카운티는 검은색 선으로 강조 표시된다. 카운티는 호수와 관련 있고, 국가에 속한다.)  Region (동일한 주제를 가진 카운티는 지도에서 연속된 지역을 형성한다.)  Country (하나의 나라는 키플레이어에 의해 형성된 하나의 subtree를 뜻한다.) Continent and Island (지도상에서 크게 연결된 국가들은 대륙을 형성한다. 작고 고립된 나라들은 섬을 형성한다. 서로 다른 나라 간의 연결은 다른 리 포스팅 관계을 표현한다.) 구조물 Route: key player가 자신의 부모 노드의 의견을 따르지 않는 경우 꺾인루트로 연결됨 건축물 Bridge: Key player가 속한 영역의 주제가 부모 노드와 다르다면 다리로 연결됨\t기하도형: 나선- 트윗 참가자의 시간에따른 활동성을 나타내고자 함\t기하도형(큐브-특정 장소에서 언제 무슨 토픽이 이루어졌는지를 나타내는 가이드라인 역할을 함) 지도+장식무늬(트윗이 발생한 장소를 나타냄)\t건축물(두 가지의 블럭:대상에 대해 표현되는 감정의 상태를 나타냄- 감정의 극성 / 감정을 나타내는 주체/ 감정의 양 등)\t장식무늬(tailored density: 등고선의 흐름으로 극성의 종류 및 강도를 나타냄)\t\t기하도형(링(원): 시간의 흐름에 따라 기록되는 다양한 주제들의 패턴을 나타냄) 기계류(렌즈): 각 토픽과 관련된 자세한 뉴스 장면을 보여줌\t 자연현상(폭포수의 낙수): 시간별로 축적되어 퍼져나가는(확산되는) 코멘트의 동향을 나타냄\t자연현상: 강의흐름(River flow) - 시간에 따라 축적되는 의견 양의 변화를 나타냄 인공물의 생성: 다리의 건설 - 시간에 따라 축적되는 각 후보자의 의견들을 나타냄\t시공간의 이동 : Root user /Key Player를 중심으로 의견 및 정보의 시간에 따른 확산\t\t\t\t자연현상(강물의 흐름과, 등고선 색상의 변화: 의견 빈도 변화와 극성의 변화를 시간에 따라 나타내고자 함)\t자연현상(강물의 폭 변화/지류의 변화/ 색상변화): 의견의 극성 및 협력과 분열 관계에 따라서 강물의 흐름이 바뀜\t\t자연현상(강물의 폭 변화: 루머 정보의 양에 따라서 달라짐, 혹은 루머에 대한 사람들의 각 평가 성향의 양에 따라서 달라짐) 인공물의 생성: 링이 시간에 따라 적절한 주제의 색상으로 생성됨\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visvar = \"장식무늬(TD) 명암도의 변화: 감정의 강도에 따라서 명암도가 달라짐\tCoopetition의 강도(power)에 따라서 강물 색상의 명암도가 달라짐\t\t 기하도형(사각형)의 색상: 의견보유자의 유형에 따라 색상을 변형함 (키 플레이어(유명인)과 커뮤니티- 분홍색/ 일반인 - 노란색)\t다리의 색상: 각 후보자의 아이덴티티를 나타냄 (힐러리: 분홍/ 트럼프: 파랑)\t색상(키워드의 색상): 키워드의 속성을 부정/긍정/중립으로 나눔 색상(노드의 색상): Repost Level에 따라 색상을 분리\t강의 색상: 최근에 진행된 토픽을 초록계열, 과거에 진행된 토픽일 수록 파란계열을 사용함\t강의 색상: 트윗이 발생된 장소에 따라 달라짐\t감정의 극성에 따라 강의 색 및 블록의 색이 결정됨 (unpleasant: 빨강, 중립: 회색, pleasant: 파랑)\t장식무늬의 색상: 감정의 극성이 긍정일경우 초록색 계열, 부정일 경우 붉은색 계열을 사용함\tCoopetition의 극성에 따라 강물의 색상이 달라짐 (긍정: green, 부정: orange)\t강물의 색상: 각 뉴스 주제에 따라서 8가지의 강의 색상이 나타남 링의 색상: 동일한 색상 적용 강의 색상(뉴스 기사의 토픽/루머에 대한 사람들의 평가 성향의 종류(질책, 무시, 퍼뜨림) 따라서 강의 색상이 달라짐) 높이: 수집되는 댓글이 최근이 될 수록 폭포의 단차 높이가 높아짐\t다리의 두께: 트윗의 양\t크기: 지역(region)의 크기 넓이: 링크(link)의 넓이\t강의 폭: 수집되는 키워드의 빈도가 많을수록 쌓이는 강의 폭이 넓어짐\t\t감정 텍스트 빈도에 따라서 블록의 두께, 강의 폭이 넓어짐\t강의 폭: 특정 시간에 수집되는 트윗의 양이 많을수록 강의 폭이 넓어짐\t강의 폭: 특정 시간에 수집되는 트윗의 양이 많을수록 강의 폭이 넓어짐\t강의 폭: 각 시간마다 언급된 토픽의 빈도수에 따라서 폭이 달라짐\t강의 폭: 루머의 양, 평가 성향의 양에 따라 폭이 달라짐 감정을 나타내는 주체가 누가 우위에 있는지에 따라 블록의 질감(모양)이 달라짐(클라이언트 우새 시 대각선라인, 에이전트 우새 시 dot 패턴, 둘 다 대등하면 플러스패턴)\t\t\t\t여러개의 강과 다리를 위치시킴: 검색한 키워드별로 여러개의 강과 다리를 위치시켜 복합 속성을 이해시킴\t\t\t\t비슷한 감정 상태를 나타내는 블록끼리 서로 근접하여 위치함\t\t트윗 텍스트의 극성에 따라서 부정적 극성의 강의 지류는 아랫쪽에, 긍정적 극성의 지류는 윗쪽에 위치함\t\t링이 시계방향을 따라서 생성: 북쪽에서부터 시계방향으로 링(주제)이 생성됨\t강의 폭: 특정 날짜에 두 후보가 남긴 트윗의 양이 많아질수록 강의 폭이 넓어짐\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vistech = \"3차원 공간 안에서 코멘트의 축적을 계층적으로 나타냄\t\t\t서로 리트윗이 되거나, 관련이 있는 코멘트를 링크로 이어줌, 의견 보유자는 사각형의 노드로 나타냄\t중요하게 언급된 키워드의 맥락을 요약하기 위해 각 키워드들의 관계를 보여주는 노드 링크 시각화가 제공됨\t\t\t\t\t각 의견을 가지는 그룹을 노드 링크 다이어그램의 형식으로 표현함\t\t\t키워드 데이터의 양을 stack graph 형태로 나타냄\t\t\t의견을 가지는 그룹을 계층적 형태로 나타내는 방법으로써 스텍 형태의 그래프를 사용함\t\t여러 주제를 가진 뉴스 토픽들이 스택 형태의 그래프를 나타내면서 강의 시각화와 조화를 이룸\t시간에 따라 감정 상태의 극성 변화를 라인플롯으로 나타냄\t\t\t\t시간에 따른 트윗의 총량 변화를 막대 그래프로 나타냄\t각 구간별로 모아진 감정 텍스트(테그)의 양을 막대 그래프로 나타냄\t\t\t\t동일한 키워드에 대해서 각 후보가 얼마만큼의 비중으로 이야기했는 지를 비교할 수 있도록 파이차트로 표현함\t\t\t\t\t\t\t\t언급된 키워드의 빈도 수에 따라 텍스트의 크기를 달리하여 시각화, 중요한 키워드를 요약하여 보여줌\t선택된 weibo 에서 주목되는 Keywords 를 보여줌\t\t각 지역, 특정 시간에 발생한 트윗의 주요 토픽을 텍스트 클라우드 형태로 나타냄\t\t\t각 구간의 자세한 트윗 텍스트 및 키워드는 텍스트 클라우드 형태로 시각화됨\t\t루머의 주요 키워드 및, 루머를 퍼뜨리는 주체들의 정보를 텍스트 클라우드로 나타냄 MDS 상에서 유사한 감정 키워드들을 군집하여 분포시킴\t\t\t\t코멘트의 축적을 기간별로 나타내고자 함\t\ttime line 뷰에서 각 Key Player에 따라 리포스팅의 시간적 패턴을 시각화함\t시간에 따라 등장하는 topic의 추이, 대상 사건에 대한 트윗의 언급 빈도를 시각화를 통해 보여줌\t시간에 따른 트윗의 패턴을 나타냄\t시간에 따른 감정 극성, 빈도의 패턴을 나타냄\t시간에 따라 변화하는 감정의 극성 및 트윗의 양을 표현하고자 타임라인을 기반으로 한 생키다이어그램 + 등고선 패턴 시각화를 제시함\t시간별로 전개되는 Coopetition의 흐름을 시각화하고자 함\t시간별로 나타나는 뉴스 토픽의 흐름을 시각화하고자 함\t시간별로 수집되는 루머 정보의 빈도를 시각화하고자 함 트윗이 발생한 실제 도시를 위치로 나타냄\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetokt = Okt()\n",
    "corpusTarget = Target.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eraseCorpusTarget = corpusTarget.replace('\\t','').replace('(','').replace(')','').replace('-','').replace('_','').replace(',','').replace(':','').replace('/','').replace('.','').replace('+','').replace('&','')\n",
    "nounTarget = targetokt.nouns(eraseCorpusTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['들', '을', '가', '이', '과', '와', '또는', '에', '대해', '를', '등', '로', '됨', '에서', '의', '될', '수', '있는', '하는', '대한', '및', '간의', '것', '수의', '함', '및', '각', '개', '널', '속', '대해', '리', '중', '별로', '은', '리지', '오', '널', '동안', '안', '위해']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] # 사용할 최종 명사 corpus\n",
    "for w in nounTarget:\n",
    "    if w not in stopwords:\n",
    "        results.append(w)\n",
    "\n",
    "word_list = pd.Series(results)\n",
    "result = word_list.value_counts().head(100)\n",
    "result\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv('riverTarget.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interOkt = Okt()\n",
    "corpusIntermediation = Intermediation.strip()\n",
    "\n",
    "eraseCorpusIntermediation = corpusIntermediation.replace('\\t','').replace('(','').replace(')','').replace('-','').replace('_','').replace(',','').replace(':','').replace('/','').replace('.','').replace('+','').replace('&','')\n",
    "\n",
    "nounIntermediation = interOkt.nouns(eraseCorpusIntermediation)\n",
    "\n",
    "intermediationResults = [] # 사용할 최종 명사 corpus\n",
    "\n",
    "for w in nounIntermediation:\n",
    "    if w not in stopwords:\n",
    "        intermediationResults.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediation_word_list = pd.Series(intermediationResults)\n",
    "intermediationResult = intermediation_word_list.value_counts().head(100)\n",
    "\n",
    "df = pd.DataFrame(intermediationResult)\n",
    "df.to_csv('riverIntermediation.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repOkt = Okt()\n",
    "corpusRepresentation = Representation.strip()\n",
    "\n",
    "eraseCorpusRepresentation = corpusRepresentation.replace('\\t','').replace('(','').replace(')','').replace('-','').replace('_','').replace(',','').replace(':','').replace('/','').replace('.','').replace('+','').replace('&','')\n",
    "\n",
    "nounRepresentation = repOkt.nouns(eraseCorpusRepresentation)\n",
    "\n",
    "representationResults = [] # 사용할 최종 명사 corpus\n",
    "\n",
    "for w in nounRepresentation:\n",
    "    if w not in stopwords:\n",
    "        representationResults.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_word_list = pd.Series(representationResults)\n",
    "representationResult = representation_word_list.value_counts().head(100)\n",
    "\n",
    "df = pd.DataFrame(representationResult)\n",
    "df.to_csv('riverRepresentation.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "visvarOkt = Okt()\n",
    "corpusVisvar = Visvar.strip()\n",
    "\n",
    "eraseCorpusVisvar = corpusVisvar.replace('\\t','').replace('(','').replace(')','').replace('-','').replace('_','').replace(',','').replace(':','').replace('/','').replace('.','').replace('+','').replace('&','')\n",
    "\n",
    "nounvisvar = visvarOkt.nouns(eraseCorpusVisvar)\n",
    "\n",
    "visvarResults = [] # 사용할 최종 명사 corpus\n",
    "\n",
    "for w in nounvisvar:\n",
    "    if w not in stopwords:\n",
    "        visvarResults.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "visvar_word_list = pd.Series(visvarResults)\n",
    "visvarResult = visvar_word_list.value_counts().head(100)\n",
    "\n",
    "df = pd.DataFrame(visvarResult)\n",
    "df.to_csv('riverVisvar.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vistechOkt = Okt()\n",
    "corpusVistech = Vistech.strip()\n",
    "\n",
    "eraseCorpusVistech = corpusVistech.replace('\\t','').replace('(','').replace(')','').replace('-','').replace('_','').replace(',','').replace(':','').replace('/','').replace('.','').replace('+','').replace('&','')\n",
    "\n",
    "nounVistech = repOkt.nouns(eraseCorpusVistech)\n",
    "\n",
    "vistechResults = [] # 사용할 최종 명사 corpus\n",
    "\n",
    "for w in nounVistech:\n",
    "    if w not in stopwords:\n",
    "        vistechResults.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vistech_word_list = pd.Series(vistechResults)\n",
    "vistechResult = vistech_word_list.value_counts().head(100)\n",
    "\n",
    "df = pd.DataFrame(vistechResult)\n",
    "df.to_csv('riverVistech.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db77b69a0df829634abc420fb187ec99886b37bfc905f4aff3cc447a1ece4fb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('pr_tensorflow2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
